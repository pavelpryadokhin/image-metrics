{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPL/DppSLSRl6ZunOTeXlmH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavelpryadokhin/image-metrics/blob/main/CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtPOBaClbxsl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pkg_resources import packaging\n",
        "import clip\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "clip.available_models()\n",
        "model, preprocess = clip.load(\"ViT-B/32\")\n",
        "model.cuda().eval()\n",
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "preprocess\n",
        "clip.tokenize(\"Hello World!\")\n"
      ],
      "metadata": {
        "id": "9x-0GOfBbzNu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n"
      ],
      "metadata": {
        "id": "UkdAj8jHcJQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Загрузка файла с локального компьютера\n",
        "uploaded = files.upload()\n",
        "\n",
        "folder_path = '/content/images/ChatGpt'\n",
        "# folder_path = '/content/1'\n",
        "\n",
        "# Укажите путь к загруженному файлу\n",
        "file_path = list(uploaded.keys())\n",
        "for file in file_path:\n",
        "  try:shutil.move(file, folder_path)\n",
        "  except: pass"
      ],
      "metadata": {
        "id": "kROMTOZhcTFs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y='/content/images/ChatGpt'\n",
        "print(y.split('/')[-1])"
      ],
      "metadata": {
        "id": "a5WgnARepnp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "# Укажите путь к загруженному архиву для распаковки\n",
        "zip_path = '/content/Картинки.zip'\n",
        "# Распаковка архива\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/images/')"
      ],
      "metadata": {
        "id": "1h9qPhdJcXNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def solution(images_path):\n",
        "  images_dict = {}\n",
        "  for image_name in os.listdir(images_path):\n",
        "      image_path = os.path.join(images_path, image_name)\n",
        "      if os.path.isfile(image_path):\n",
        "          key = int(image_name.replace(\",\", \".\").split(\".\")[0])\n",
        "          if key in images_dict:\n",
        "              images_dict[key].append(image_path)\n",
        "          else:\n",
        "              images_dict[key] = [image_path]\n",
        "  texts={1:\"wrench\", 2:\"a wrench in the hands of a master who repairs a car engine\",\n",
        "        3: \"a screwdriver\", 4:\"there are construction tools and a screwdriver on the table\",\n",
        "        5: \"ladle furnaces in steel production\",6: \"ladle furnaces in steel production with a number on the ladle\",\n",
        "        7:\"box on the conveyor belt\", 8:\"a box on a conveyor belt with a barcode\"}\n",
        "\n",
        "\n",
        "  def foo(images_dict,text):\n",
        "    original_images = []\n",
        "    images = []\n",
        "    for path in images_dict:\n",
        "      image = Image.open(path).convert(\"RGB\")\n",
        "      original_images.append(image)\n",
        "      images.append(preprocess(image))\n",
        "    image_input = torch.tensor(np.stack(images)).cuda()\n",
        "    text_tokens = clip.tokenize([\"This is \" +  text]).cuda()\n",
        "    with torch.no_grad():\n",
        "      image_features = model.encode_image(image_input).float()\n",
        "      text_features = model.encode_text(text_tokens).float()\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "    similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "\n",
        "    return [np.median(similarity),np.mean(similarity), np.std(similarity),similarity.tolist()[0]]\n",
        "\n",
        "  res=dict()\n",
        "\n",
        "  for key in images_dict:\n",
        "    res[key]=foo(images_dict[key],texts[key])\n",
        "  return res\n",
        "\n",
        "\n",
        "#   print(texts[key])\n",
        "#   print(res[-1][-1])\n",
        "#   print('медиана  ', round(res[-1][0],2))\n",
        "#   print('среднее  ', round(res[-1][1],2))\n",
        "#   print('ско  ', round(res[-1][2],2))\n",
        "# print(res)\n",
        "\n",
        "\n",
        "images_path = ['/content/images/ChatGpt','/content/images/DeepDream','/content/images/Kandinsky','/content/images/Midjourney','/content/images/Stable Diffusion','/content/images/dreamstudio','/content/images/shedevrum']\n",
        "ans=dict()\n",
        "\n",
        "for i in images_path:\n",
        "  ans[i.split('/')[-1]]=solution(i)\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "W7PE2GjBcX-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for res in ans:\n",
        "  print(res)\n",
        "  for val in sorted(ans[res]):\n",
        "    print(round(ans[res][val][1],2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9atErJepvbef",
        "outputId": "1e48bc94-7553-49a2-acda-6cc242009403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGpt\n",
            "0.29\n",
            "0.3\n",
            "0.29\n",
            "0.28\n",
            "0.32\n",
            "0.32\n",
            "0.25\n",
            "0.28\n",
            "DeepDream\n",
            "0.23\n",
            "0.28\n",
            "0.3\n",
            "0.28\n",
            "0.32\n",
            "0.3\n",
            "0.27\n",
            "0.29\n",
            "Kandinsky\n",
            "0.29\n",
            "0.31\n",
            "0.31\n",
            "0.29\n",
            "0.33\n",
            "0.33\n",
            "0.24\n",
            "0.26\n",
            "Midjourney\n",
            "0.26\n",
            "0.31\n",
            "0.3\n",
            "0.27\n",
            "0.32\n",
            "0.32\n",
            "0.26\n",
            "0.29\n",
            "Stable Diffusion\n",
            "0.28\n",
            "0.29\n",
            "0.3\n",
            "0.27\n",
            "0.32\n",
            "0.32\n",
            "0.26\n",
            "0.28\n",
            "dreamstudio\n",
            "0.3\n",
            "0.3\n",
            "0.29\n",
            "0.28\n",
            "0.32\n",
            "0.33\n",
            "0.25\n",
            "0.28\n",
            "shedevrum\n",
            "0.27\n",
            "0.29\n",
            "0.31\n",
            "0.27\n",
            "0.32\n",
            "0.32\n",
            "0.24\n",
            "0.27\n"
          ]
        }
      ]
    }
  ]
}